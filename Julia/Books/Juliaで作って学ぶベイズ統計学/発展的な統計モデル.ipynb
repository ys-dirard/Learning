{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions, PyPlot, LinearAlgebra, ForwardDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set_options (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function set_options(ax, xlabel, ylabel, title; grid=true, gridy=false, legend=false)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    if grid\n",
    "        if gridy\n",
    "            ax.grid(axis=\"y\")\n",
    "        else\n",
    "            ax.grid()\n",
    "        end\n",
    "    end\n",
    "    legend && ax.legend()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unzip (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye(n) = Diagonal{Float64}(I, n)\n",
    "\n",
    "unzip(a) = map(x->getfield.(a, x), fieldnames(eltype(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inference_wrapper_HMC (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function HMC(log_p_tilde, μ₀; maxiter::Int=100_000, L::Int=100, ϵ::Float64=1e-1)\n",
    "    function leapflog(grad, p_in, μ_in, L, ϵ)\n",
    "        μ = μ_in\n",
    "        p = p_in + 0.5*ϵ*grad(μ)\n",
    "        for l in 1:L-1\n",
    "            μ += ϵ*p\n",
    "            p += ϵ*grad(μ)\n",
    "        end\n",
    "        μ += ϵ*p\n",
    "        p += 0.5*ϵ*grad(μ)\n",
    "        p, μ\n",
    "    end\n",
    "    \n",
    "    grad(μ) = ForwardDiff.gradient(log_p_tilde, μ)\n",
    "    \n",
    "    D = length(μ₀)\n",
    "    μ_samples = Array{typeof(μ₀[1]), 2}(undef, D, maxiter)\n",
    "    \n",
    "    μ_samples[:, 1] = μ₀\n",
    "    \n",
    "    num_accepted = 1\n",
    "    \n",
    "    for i in 2:maxiter\n",
    "        p_in = randn(size(μ₀))\n",
    "        \n",
    "        p_out, μ_out = leapflog(grad, p_in, μ_samples[:, i-1], L, ϵ)\n",
    "        \n",
    "        μ_in = μ_samples[:, i-1]\n",
    "        log_r = (log_p_tilde(μ_out) +\n",
    "                        logpdf(MvNormal(zeros(D), eye(D)), vec(p_out))) - \n",
    "                        (log_p_tilde(μ_in) + \n",
    "                        logpdf(MvNormal(zeros(D), eye(D)), vec(p_in)))\n",
    "        \n",
    "        is_accepted = min(1, exp(log_r)) > rand()\n",
    "        new_sample = is_accepted ? μ_out : μ_in\n",
    "        \n",
    "        μ_samples[:, i] = new_sample\n",
    "        \n",
    "        num_accepted += is_accepted\n",
    "    end\n",
    "    \n",
    "    μ_samples, num_accepted\n",
    "end\n",
    "\n",
    "function inference_wrapper_HMC(log_joint, params, w_init; maxiter::Int=100000, L::Int=100, ϵ::Float64=1e-1)\n",
    "    ulp(w) = log_joint(w, params...)\n",
    "    HMC(ulp, w_init; maxiter=maxiter, L=L, ϵ=ϵ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ポアソン回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(Y, w|X) = p(w) \\prod_{n=1}^N p(y_n|x_n, w) = \\mathcal{N}(w|0, \\sigma^2 I) \\prod_{n=1}^N Poisson(y_n|\\exp(w^Tx_n))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = [-2, -1.5, 0.5, 0.7, 1.2]\n",
    "\n",
    "y_obs = [0.0, 0, 2, 1, 8]\n",
    "\n",
    "fig, ax = subplots()\n",
    "ax.scatter(x_obs, y_obs)\n",
    "set_options(ax, \"x\", \"y\", \"data (N = $(length(x_obs)))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_joint(w, x, y) = \n",
    "    sum(logpdf.(Poisson.(exp.(w[1]*x .+ w[2])), y)) + \n",
    "    logpdf(Normal(0, 1.0), w[1]) + \n",
    "    logpdf(Normal(0, 1.0), w[2])\n",
    "\n",
    "params = (x_obs, y_obs)\n",
    "ulp(w) = log_joint(w, params...)\n",
    "        \n",
    "w_init = randn(2)\n",
    "\n",
    "maxiter = 300\n",
    "param_posterior, num_accepted = inference_wrapper_HMC(log_joint, params, w_init, maxiter=maxiter)\n",
    "\n",
    "# HMC\n",
    "fig, axes = subplots(2, 1, figsize=(8, 4))\n",
    "axes[1].plot(param_posterior[1, :])\n",
    "set_options(axes[1], \"iteration\", \"w₁\", \"w₁ sequence (HMC)\")\n",
    "axes[2].plot(param_posterior[2, :])\n",
    "set_options(axes[2], \"iteration\", \"w₂\", \"w₂ sequence (HMC)\")\n",
    "tight_layout()\n",
    "println(\"acceptance rate (HMC) = $(num_accepted / maxiter)\")\n",
    "\n",
    "fig, ax = subplots()\n",
    "ax.scatter(param_posterior[1, :], param_posterior[2, :], alpha=0.1)\n",
    "set_options(ax, \"w₁\", \"w₂\", \"samples from posterior\")\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = range(-2, 2, length=100)\n",
    "\n",
    "fig, ax = subplots()\n",
    "\n",
    "# HMC\n",
    "for i in 1:size(param_posterior, 2)\n",
    "    w₁, w₂ = param_posterior[:, i]\n",
    "    f(x) = exp.(w₁*x + w₂)\n",
    "    ax.plot(xs, f.(xs), \"g\", alpha=0.1)\n",
    "end\n",
    "ax.plot(x_obs, y_obs, \"ko\")\n",
    "ax.set_xlim(extrema(xs))\n",
    "ax.set_ylim([-1, 15])\n",
    "set_options(ax, \"x\", \"y\", \"predicive distribution (HMC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 階層ベイズモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = []\n",
    "y_obs = []\n",
    "\n",
    "push!(x_obs, [0.3, 0.4])\n",
    "push!(y_obs, [4.0, 3.7])\n",
    "\n",
    "\n",
    "push!(x_obs, [0.2, 0.4, 0.9])\n",
    "push!(y_obs, [6.0, 7.2, 9.4])\n",
    "\n",
    "push!(x_obs, [0.6, 0.8, 0.9])\n",
    "push!(y_obs, [6.0, 6.9, 7.8])\n",
    "\n",
    "fig, ax = subplots()\n",
    "ax.plot(x_obs[1], y_obs[1], \"or\", label=\"class1\")\n",
    "ax.plot(x_obs[2], y_obs[2], \"xg\", label=\"class2\")\n",
    "ax.plot(x_obs[3], y_obs[3], \"^b\", label=\"class3\")\n",
    "set_options(ax, \"x\", \"y\", \"data\", legend=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function linear_fit(y, x)\n",
    "    N = length(x)\n",
    "    w₁ = sum((y .- mean(y)) .* x) / sum((x .- mean(x)) .* x)\n",
    "    w₂ = mean(y) - w₁*mean(x)\n",
    "    w₁, w₂\n",
    "end\n",
    "\n",
    "w₁, w₂ = linear_fit(vcat(y_obs...), vcat(x_obs...))\n",
    "\n",
    "w₁s = []\n",
    "w₂s = []\n",
    "for i in 1:3\n",
    "    w₁_tmp, w₂_tmp = linear_fit(y_obs[i], x_obs[i])\n",
    "    push!(w₁s, w₁_tmp)\n",
    "    push!(w₂s, w₂_tmp)\n",
    "end\n",
    "\n",
    "xs = range(0, 1, length=100)\n",
    "\n",
    "fig, axes = subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "axes[1].plot(xs, w₁ .* xs .+ w₂, \"-k\")\n",
    "\n",
    "axes[2].plot(xs, w₁s[1] .* xs .+ w₂s[1], \"-r\")\n",
    "axes[2].plot(xs, w₁s[2] .* xs .+ w₂s[2], \"-g\")\n",
    "axes[2].plot(xs, w₁s[3] .* xs .+ w₂s[3], \"-b\")\n",
    "\n",
    "for ax in axes\n",
    "    ax.plot(x_obs[1], y_obs[1], \"or\", label=\"class1\")\n",
    "    ax.plot(x_obs[2], y_obs[2], \"xg\", label=\"class2\")\n",
    "    ax.plot(x_obs[3], y_obs[3], \"^b\", label=\"class3\")\n",
    "end\n",
    "\n",
    "set_options(axes[1], \"x\", \"y\", \"(a) single regression\", legend=true)\n",
    "set_options(axes[2], \"x\", \"y\", \"(b) multiple regressions\", legend=true)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "階層ベイズに直す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(Y, w|X) = p(w_1)p(w_2) \\prod_{i=1}^3 \\left\\{p(w_1^{(i)}|w_1)p(w_2^{(2)}|w_2) \\prod_{n=1}^{N_i} p(y_n^{(i)}|x_n^{(i)}, w_1^{(i)}, w_2^{(i)})\\right\\}$$\n",
    "\n",
    "今回$w_1, w_2$はハイパーパラメータ\n",
    "$$p(w_1) = \\mathcal{N}(w_1|0, 10.0)$$\n",
    "$$p(w_2) = \\mathcal{N}(w_2|0, 10.0)$$\n",
    "\n",
    "ハイパーパラメータが生成されると各クラスのパラメータが生成される\n",
    "$$p(w_1^{(i)}|w_1) = \\mathcal{N}(w_1^{(i)}|w_1, 1.0)$$\n",
    "$$p(w_2^{(i)}|w_2) = \\mathcal{N}(w_2^{(i)}|w_2, 1.0)$$\n",
    "\n",
    "最後の部分は尤度\n",
    "$$p(y_n^{(i)}|x_n^{(i)}, w_1^{(i)}, w_2^{(i)}) = \\mathcal{N}(y_n^{(i)}|w_1^{(i)}x_n^{(i)} + w_2^{i}, 1.0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@views hyper_prior(w) = logpdf(Normal(0, 10.0), w[1]) + logpdf(Normal(0, 10.0), w[2])\n",
    "@views prior(w) = sum(logpdf.(Normal.(w[1], 1.0), w[3:5])) + sum(logpdf.(Normal.(w[2], 1.0), w[6:8]))\n",
    "@views log_likelihood(y, x, w) = sum([sum(logpdf.(Normal.(y[i], 1.0), w[2+1].*x[i] .+ w[2+i+3])) for i in 1:3])\n",
    "\n",
    "log_joint(w, x, y) = hyper_prior(w) + prior(w) + log_likelihood(y_obs, x_obs, w)\n",
    "params = (y_obs, x_obs)\n",
    "ulp(w) = hyper_prior(w) + prior(w) + log_likelihood(w, params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxiter = 1000\n",
    "w_init = randn(8)\n",
    "param_posterior, num_accepted = inference_wrapper_HMC(log_joint, params, w_init, maxiter=maxiter, L=100, ϵ=0.01)\n",
    "\n",
    "fig, axes = subplots(1, 3, sharey=true, figsize=(12, 4))\n",
    "\n",
    "for i in 1:3\n",
    "    for j in 1:size(param_posterior, 2)\n",
    "        w₁, w₂ = param_posterior[[2+i, 2+i+3], j]\n",
    "        axes[i].plot(xs, w₁ .* xs .+ w₂, \"c-\", alpha=0.01)\n",
    "    end\n",
    "    set_options(axes[i], \"x\", \"y\", \"class $(i)\")\n",
    "end\n",
    "\n",
    "axes[1].plot(x_obs[1], y_obs[1], \"or\", label=\"class1\")\n",
    "axes[2].plot(x_obs[2], y_obs[2], \"xg\", label=\"class2\")\n",
    "axes[3].plot(x_obs[3], y_obs[3], \"^b\", label=\"class3\")\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = []\n",
    "y_obs = []\n",
    "\n",
    "push!(x_obs, [0.1, 0.3, 0.4, 0.5, 0.6, 0.9])\n",
    "push!(y_obs, [4.0, 4.0, 3.7, 3.8, 3.9, 3.7])\n",
    "\n",
    "push!(x_obs, [0.2, 0.4, 0.9])\n",
    "push!(y_obs, [6.0, 7.2, 9.4])\n",
    "\n",
    "push!(x_obs, [0.6, 0.8, 0.9])\n",
    "push!(y_obs, [6.0, 6.9, 7.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@views hyper_prior(w) = logpdf(Normal(0, 10.0), w[1]) + logpdf(Normal(0, 10.0), w[2])\n",
    "@views prior(w) = sum(logpdf.(Normal.(w[1], 1.0), w[3:5])) + sum(logpdf.(Normal.(w[2], 1.0), w[6:8]))\n",
    "@views log_likelihood(y, x, w) = sum([sum(logpdf.(Normal.(y[i], 1.0), w[2+i].*x[i] .+ w[2+i+3])) for i in 1:3])\n",
    "\n",
    "log_joint(w, x, y) = hyper_prior(w) + prior(w) + log_likelihood(y_obs, x_obs, w)\n",
    "params = (y_obs, x_obs)\n",
    "ulp(w) = hyper_prior(w) + prior(w) + log_likelihood(w, params...)\n",
    "\n",
    "maxiter = 1000\n",
    "w_init = randn(8)\n",
    "param_posterior, num_accepted = inference_wrapper_HMC(log_joint, params, w_init, maxiter=maxiter, L=100, ϵ=0.01)\n",
    "\n",
    "fig, axes = subplots(1, 3, sharey=true, figsize=(12, 4))\n",
    "\n",
    "for i in 1:3\n",
    "    for j in 1:size(param_posterior, 2)\n",
    "        w₁, w₂ = param_posterior[[2+i, 2+i+3], j]\n",
    "        axes[i].plot(xs, w₁ .* xs .+ w₂, \"c-\", alpha=0.01)\n",
    "    end\n",
    "    set_options(axes[i], \"x\", \"y\", \"class $(i)\")\n",
    "end\n",
    "\n",
    "axes[1].plot(x_obs[1], y_obs[1], \"or\", label=\"class1\")\n",
    "axes[2].plot(x_obs[2], y_obs[2], \"xg\", label=\"class2\")\n",
    "axes[3].plot(x_obs[3], y_obs[3], \"^b\", label=\"class3\")\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状態空間モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "状態空間モデル$\\rightarrow$各データの間に時間的依存性があると仮定される場合に有用  \n",
    "状態変数$X = \\{ x_1, x_2, ..., x_N \\}$に対しマルコフ連鎖を考える\n",
    "\n",
    "$$x_1 \\sim \\mathcal{N}(x_1|\\mu, \\Sigma_1)$$\n",
    "$$x_n \\sim \\mathcal{N}(x_n|x_{n-1}, \\Sigma_x) \\quad for \\quad n=2, 3, ..., N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スムージング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ系列$Y$から背後に存在すると仮定される状態変数$X$を抽出することを考える\n",
    "\n",
    "$$p(X|Y) = \\dfrac{p(Y|X)p(X)}{p(Y)} \\propto \\left\\{ p(x_1)\\prod_{n=2}^N p(x_n|x_{n-1})\\right\\}\\left\\{ \\prod_{n=1}^N p(y_n|x_n)\\right\\}$$\n",
    "\n",
    "観測ノイズの多い座標系列データ$Y$から、ノイズを除去した真の位置$X$を推定する問題に使えたりする(GPS等)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "\n",
    "D = 2\n",
    "\n",
    "y_obs = \n",
    "    [1.9 0.2 0.1 1.4 0.3 1.3 1.6 1.5 1.6 2.4 #=\n",
    "=# 1.7 3.6 2.8 1.6 3.0 2.8 5.1 5.2 6.0 6.4;\n",
    "      0.1 0.2 0.9 1.5 4.0 5.0 6.3 5.8 6.4 7.5#=\n",
    "=# 6.7 7.6 8.7 8.2 8.5 9.6 8.4 8.4 8.4 9.0]\n",
    "\n",
    "fig, ax = subplots(figsize=(6, 6))\n",
    "ax.plot(y_obs[1, :], y_obs[2, :], \"kx--\")\n",
    "ax.text(y_obs[1, 1], y_obs[2, 1], \"start\", color=\"r\")\n",
    "ax.text(y_obs[1, end], y_obs[2, end], \"goal\", color=\"r\")\n",
    "set_options(ax, \"y₁\", \"y₂\", \"2dim data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期状態に与えるノイズ\n",
    "σ₁ = 100.0\n",
    "\n",
    "# 状態遷移に仮定するノイズ\n",
    "σ_x = 1.0\n",
    "\n",
    "# 観測に仮定するノイズ\n",
    "σ_y = 1.0\n",
    "\n",
    "# 状態の遷移系列に関する対数密度\n",
    "@views transition(x, σ₁, σ_x, D, N) = \n",
    "        logpdf(MvNormal(zeros(D), σ₁*eye(D)), x[:, 1]) + \n",
    "        sum([logpdf(MvNormal(x[:, n-1], σ_x*eye(D)), x[:, n]) for n in 2:N])\n",
    "# 観測データに対する対数密度\n",
    "@views observation(x, y, σ_y, D, N) = \n",
    "        sum([logpdf(MvNormal(x[:, n], σ_y*eye(D)), y[:, n]) for n in 1:N])\n",
    "\n",
    "# 対数同時分布\n",
    "log_joint_tmp(x, y, σ₁, σ_x, σ_y, D, N) = \n",
    "        transition(x, σ₁, σ_x, D, N) + \n",
    "        observation(x, y, σ_y, D, N)\n",
    "\n",
    "log_joint(x_vec, y, σ₁, σ_x, σ_y, D, N) = \n",
    "        log_joint_tmp(reshape(x_vec, D, N), y, σ₁, σ_x, σ_y, D, N)\n",
    "params = (y_obs, σ₁, σ_x, σ_y, D, N)\n",
    "\n",
    "ulp(x_vec) = log_joint(x_vec, params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = randn(D*N)\n",
    "\n",
    "maxiter = 1000\n",
    "\n",
    "samples, num_accepted = inference_wrapper_HMC(log_joint, params, x_init, maxiter=maxiter)\n",
    "\n",
    "println(\"acceptance rate = $(num_accepted / maxiter)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots(figsize=(6, 6))\n",
    "for i in 1:maxiter\n",
    "    x = reshape(samples[:, i], D, N)\n",
    "    ax.plot(x[1, :], x[2, :], \"go--\", alpha=10.0/maxiter)\n",
    "end\n",
    "\n",
    "ax.plot(y_obs[1, :], y_obs[2, :], \"kx--\", label=\"observation (Y)\")\n",
    "\n",
    "mean_trace = reshape(mean(samples, dims=2), D, N)\n",
    "ax.plot(mean_trace[1, :], mean_trace[2, :], \"ro--\", label=\"estimated position (X)\")\n",
    "\n",
    "set_options(ax, \"y₁\", \"y₂\", \"2dim data\", legend=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回帰への適用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力値$z$から出力値$y$を予測するモデルを考える、背後に直接観測できない経時的な変化成分$x$が存在すると仮定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(Y, X, w|Z) = p(Y|X, Z, w)p(X)p(w) = p(w)\\left \\{p(x_1)\\prod_{n=2}^N p(x_n|x_{n-1}) \\right \\} \\left \\{\\prod_{n=1}^N p(y_n|x_{n}, z_n, w) \\right \\}$$\n",
    "\n",
    "ただし\n",
    "$$p(w) = \\mathcal{N}(w_1|0, \\sigma_w)\\mathcal{N}(w_2|0, \\sigma_w)$$\n",
    "$$p(x_1) = \\mathcal{N}(x_1|0, \\sigma_1)$$\n",
    "$$p(x_n|x_{n-1}) = \\mathcal{N}(x_n|x_{n-1}, \\sigma_x)$$\n",
    "$$p(y_n|x_n, z_n, w) = \\mathcal{N}(y_n|w_1x_n + w_2 + x_n, \\sigma_y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "\n",
    "z_obs = [10, 10, 10, 10, 10, 10, 10, 10, 10, 15,\n",
    "                 15, 15, 15, 15, 15, 15, 8, 8, 8, 8]\n",
    "\n",
    "y_obs = [67, 64, 60, 60, 57, 54, 51, 51, 49, 63, \n",
    "                 62, 62, 58, 57, 53, 51, 24, 22, 23, 19]\n",
    "\n",
    "fig, ax = subplots()\n",
    "ax.scatter(z_obs, y_obs)\n",
    "set_options(ax, \"z\", \"y\", \"data (scatter)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "axes[1].plot(y_obs)\n",
    "set_options(axes[1], \"time\", \"y\", \"time series (y_obs)\")\n",
    "\n",
    "axes[2].plot(z_obs)\n",
    "set_options(axes[2], \"time\", \"z\", \"time series (z_obs)\")\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期状態に与えるノイズ\n",
    "σ₀ = 10.0\n",
    "\n",
    "# 状態遷移に仮定するノイズ\n",
    "σ_x = 1.0\n",
    "\n",
    "# 観測に仮定するノイズ\n",
    "σ_y = 0.5\n",
    "\n",
    "# パラメータに仮定するノイズ\n",
    "σ_w = 100.0\n",
    "\n",
    "# パラメータの事前分布\n",
    "prior(w, σ_w) = logpdf(MvNormal(zeros(2), σ_w*eye(2)), w)\n",
    "\n",
    "# 状態の遷移系列に関する対数密度\n",
    "@views transition(x, σ₀, σ_x) = \n",
    "        logpdf(Normal(0, σ₀), x[1]) + \n",
    "        sum(logpdf.(Normal.(x[1:N-1], σ_x), x[2:N]))\n",
    "\n",
    "# 観測データに対する対数密度\n",
    "@views observation(x, y, z, w) = \n",
    "        sum(logpdf.(Normal.(w[1]*z .+ w[2] + x, σ_y), y))\n",
    "\n",
    "# 対数同時分布\n",
    "log_joint_tmp(x, w, y, z, σ_w, σ₀, σ_x) = \n",
    "        transition(x, σ₀, σ_x) + \n",
    "        observation(x, y, z, w) + prior(w, σ_w)\n",
    "\n",
    "@views log_joint(x_vec, y, z, σ_w, σ₀, σ_x) = \n",
    "        transition(x_vec[1:N], σ₀, σ_x) + \n",
    "        observation(x_vec[1:N], y, z, x_vec[N+1:N+2]) + prior(x_vec[N+1:N+2], σ_w)\n",
    "params = (y_obs, z_obs, σ_w, σ₀, σ_x)\n",
    "\n",
    "x_init = randn(N+2)\n",
    "maxiter = 1000\n",
    "samples, num_accepted = inference_wrapper_HMC(log_joint, params, x_init, maxiter=maxiter, L=100, ϵ=1e-2)\n",
    "\n",
    "println(\"acceptance rate = $(num_accepted / maxiter)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = subplots(5, 1, figsize=(8, 15))\n",
    "\n",
    "axes[1].plot(y_obs)\n",
    "set_options(axes[1], \"time\", \"y\", \"output data (Y)\")\n",
    "\n",
    "axes[2].plot(z_obs)\n",
    "set_options(axes[2], \"time\", \"z\", \"input data (Z)\")\n",
    "\n",
    "for i in 1:maxiter\n",
    "    w₁, w₂ = samples[[N+1, N+2], i]\n",
    "    axes[3].plot(w₁*z_obs .+ w₂, \"g-\", alpha=10/maxiter)\n",
    "end\n",
    "set_options(axes[3], \"time\", \"w₁z + w₂\", \"regression\")\n",
    "\n",
    "for i in 1:maxiter\n",
    "    x = samples[1:N, i]\n",
    "    axes[4].plot(x, \"g-\", alpha=10/maxiter)\n",
    "end\n",
    "set_options(axes[4], \"time\", \"x\", \"time series\")\n",
    "\n",
    "for i in 1:maxiter\n",
    "    w₁, w₂ = samples[[N+1, N+2], i]\n",
    "    x = samples[1:N, i]\n",
    "    axes[5].plot(w₁*z_obs .+ w₂ + x, \"g-\", alpha=10/maxiter)\n",
    "end\n",
    "axes[5].plot(y_obs, \"k\", label=\"Y_obs\")\n",
    "set_options(axes[5], \"time\", \"w₁z + w₂ + x\", \"regression + time series\", legend=true)\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
